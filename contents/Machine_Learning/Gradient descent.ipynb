{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一. Model Representation\n",
    "\n",
    "在给定训练集的情况下，学习函数h：X→Y，使得h（x）是y的相应值的“好”预测器。由于历史原因，这个函数h被称为假设。\n",
    "\n",
    "\n",
    "![](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/H6qTdZmYEeaagxL7xdFKxA_2f0f671110e8f7446bb2b5b2f75a8874_Screenshot-2016-10-23-20.14.58.png?expiry=1520812800000&hmac=_RVGu2JUuidIVW13kchbboKgBuSg4f9NF1TW5tOlrJI)\n",
    "\n",
    "\n",
    "通过输入住房面积 x，通过学习好的函数，输出房子的估价。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "------------------------------------------------------\n",
    "\n",
    "\n",
    "# 二. Cost Function\n",
    "\n",
    "代价函数是线性回归中的一个应用，在线性回归中，要解决的一个问题就是最小化问题。\n",
    "\n",
    "假设在一元线性回归中，在一个训练集中，我们需要找到一条直线能和该训练集中的点最接近。假设直线方程为 \n",
    "\n",
    "$$h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x$$\n",
    "\n",
    "\n",
    "如何选择 $\\theta_{0}$、$\\theta_{1}$，使得 $h_{\\theta}(x)$ 更接近于训练集 (x,y) ？\n",
    "\n",
    "上述问题可以转换为求 $$ \\rm{CostFunction} = \\rm{F({\\theta_{0}},{\\theta_{1}})}  = \\frac{1}{2m}\\sum_{i = 1}^{m} (h_{\\theta}(x^{(i)})-y^{(i)})^2 \\tag {平方误差代价函数}$$  求最小值$$\\min_{{\\theta_{0}} {\\theta_{1}}} \\rm{F({\\theta_{0}},{\\theta_{1}})} $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 三. Gradient Descent 梯度下降\n",
    "\n",
    "\n",
    "梯度下降的主要思想：\n",
    "\n",
    "1. 初始化 ${\\theta_{0}}$ 和 ${\\theta_{1}}$ , ${\\theta_{0}}$ = 0 , ${\\theta_{1}}$ = 0\n",
    "2. 不断的改变 ${\\theta_{0}}$ 和 ${\\theta_{1}}$ 值，不断减少 $F({\\theta_{0}},{\\theta_{1}})$ 直至达到最小值（或者局部最小）。\n",
    "\n",
    "\n",
    "![](https://ob6mci30g.qnssl.com/Blog/ArticleImage/68_1.png)\n",
    "\n",
    "\n",
    "想象成下山，如何下山的速度最快？这里涉及到了下山的速度，即步长。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/bn9SyaDIEeav5QpTGIv-Pg_0d06dca3d225f3de8b5a4a7e92254153_Screenshot-2016-11-01-23.48.26.png?expiry=1520812800000&hmac=fLLO2jY4ccqkRtqtkT-fjubQEPUbuyeNhX1AYc-oCCk)\n",
    "\n",
    "有趣的是换旁边一个点，下山，找到的最优解可能就是另一个了。这也是梯度下降的一个特点。它会找到所有的局部最优解出来。\n",
    "\n",
    "梯度下降算法，不断更新：\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\rm{temp}0 &:= {\\theta_{0}} - \\alpha * \\frac{\\partial }{\\partial {\\theta_{0}}}\\rm{F({\\theta_{0}},{\\theta_{1}})} \\tag {第一步} \\\\\n",
    "\\rm{temp}1 &:= {\\theta_{1}} - \\alpha * \\frac{\\partial }{\\partial {\\theta_{1}}}\\rm{F({\\theta_{0}},{\\theta_{1}})} \\tag {第二步} \\\\\n",
    "{\\theta_{0}} &:= \\rm{temp}0 \\tag {第三步} \\\\\n",
    "{\\theta_{1}} &:= \\rm{temp}1 \\tag {第四步} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "直到收敛。注意 ${\\theta_{0}}$ 和 ${\\theta_{1}}$ 值要**同时更新**，**切记不要求一次导更新一次！**\n",
    "\n",
    "\n",
    "$\\alpha$ 被称作为学习速率。\n",
    "\n",
    "\n",
    "![](https://camo.githubusercontent.com/acf4bf18294bd5379abf9cb1485aab86d65dfc04/68747470733a2f2f7773322e73696e61696d672e636e2f6c617267652f303036744e6337396c7931666d676e32336c6e7a6a673330393830676f67736f2e676966)\n",
    "\n",
    "如果 $\\alpha$ 被设置的很小，需要很多次循环才能到底最低点。\n",
    "如果 $\\alpha$ 被设置的很大，来来回回可能就会离最低点越来越远，**会导致无法收敛，甚至发散**。\n",
    "\n",
    "当快要到最低点的时候，梯度下降会越来越慢，因为 $ \\frac{\\partial }{\\partial {\\theta}}$ 越来越小。\n",
    "\n",
    "------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四. Linear Regression 线性回归\n",
    "\n",
    "梯度下降是很常用的算法，它不仅被用在线性回归，还用在线性回归模型、平方误差代价函数中。\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial }{\\partial {\\theta_{j}}}\\rm{F({\\theta_{0}},{\\theta_{1}})} & = \\frac{\\partial }{\\partial {\\theta_{j}}} \\frac{1}{2m}\\sum_{i = 1}^{m} (h_{\\theta}(x^{(i)})-y^{(i)})^2\\\\\n",
    "& = \\frac{\\partial }{\\partial {\\theta_{j}}} \\frac{1}{2m}\\sum_{i = 1}^{m} (\\theta_{0} + {\\theta_{1}}x^{(i)}-y^{(i)})^2 \\\\\n",
    "& = \\frac{1}{2m} \\frac{\\partial }{\\partial {\\theta_{j}}} \\sum_{i = 1}^{m} (\\theta_{0}^{2} + 2\\theta_{0}\\theta_{1}x^{(i)} - 2\\theta_{0}y^{(i)} + \\theta_{1}^2(x^{(i)})^2 - 2\\theta_{1}x^{(i)}y^{(i)} + (y^{(i)})^2) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "---------------------------------------------------------------\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial }{\\partial {\\theta_{0}}}\\rm{F({\\theta_{0}},{\\theta_{1}})} &= \\frac{1}{2m} \\frac{\\partial }{\\partial {\\theta_{0}}} \\sum_{i = 1}^{m}(2\\theta_{0} + 2\\theta_{1}x^{(i)} - 2y^{(i)}) \\\\\n",
    "&= \\frac{1}{m} \\sum_{i = 1}^{m}(\\theta_{0} + \\theta_{1}x^{(i)} - y^{(i)}) = \\frac{1}{m} \\sum_{i = 1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)}) \\\\\n",
    "\\frac{\\partial }{\\partial {\\theta_{1}}}\\rm{F({\\theta_{0}},{\\theta_{1}})} &=  \\frac{1}{2m} \\frac{\\partial }{\\partial {\\theta_{1}}} \\sum_{i = 1}^{m}(2\\theta_{0}x^{(i)} + 2\\theta_{1}(x^{(i)})^2 - 2x^{(i)}y^{(i)})\\\\\n",
    "&= \\frac{1}{m} \\sum_{i = 1}^{m}(\\theta_{0} + \\theta_{1}x^{(i)} - y^{(i)}) * x^{(i)} = \\frac{1}{m} \\sum_{i = 1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)}) * x^{(i)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "---------------------------------------------------------------\n",
    "\n",
    "梯度下降算法：\n",
    "\n",
    "\\begin{align*}\n",
    "\\rm{temp}0 &:= {\\theta_{0}} - \\alpha * \\frac{\\partial }{\\partial {\\theta_{0}}}\\rm{F({\\theta_{0}},{\\theta_{1}})} = {\\theta_{0}} - \\alpha * \\frac{1}{m} \\sum_{i = 1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)}) \\tag {第一步} \\\\\n",
    "\\rm{temp}1 &:= {\\theta_{1}} - \\alpha * \\frac{\\partial }{\\partial {\\theta_{1}}}\\rm{F({\\theta_{0}},{\\theta_{1}})} = {\\theta_{1}} - \\alpha * \\frac{1}{m} \\sum_{i = 1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)}) * x^{(i)} \\tag {第二步} \\\\\n",
    "{\\theta_{0}} &:= \\rm{temp}0 \\tag {第三步} \\\\\n",
    "{\\theta_{1}} &:= \\rm{temp}1 \\tag {第四步} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5bb7a04fd0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[2.5], [3.5], [6.3], [9.9], [9.91], [8.02],\n",
    "                    [4.5], [5.5], [6.23], [7.923], [2.941], [5.02],\n",
    "                    [6.34], [7.543], [7.546], [8.744], [9.674], [9.643],\n",
    "                    [5.33], [5.31], [6.78], [1.01], [9.68],\n",
    "                    [9.99], [3.54], [6.89], [10.9]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[3.34], [3.86], [5.63], [7.78], [10.6453], [8.43],\n",
    "                    [4.75], [5.345], [6.546], [7.5754], [2.35654], [5.43646],\n",
    "                    [6.6443], [7.64534], [7.546], [8.7457], [9.6464], [9.74643],\n",
    "                    [6.32], [6.42], [6.1243], [1.088], [10.342],\n",
    "                    [9.24], [4.22], [5.44], [9.33]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5b867ac7f0>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(x_train, y_train, 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GitHub Repo：[Halfrost-Field](https://github.com/halfrost/Halfrost-Field)\n",
    "> \n",
    "> Follow: [halfrost · GitHub](https://github.com/halfrost)\n",
    ">\n",
    "> Source: [https://github.com/halfrost/Halfrost-Field/blob/master/contents/Model\\_and\\_Cost\\_Function.md](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Model_and_Cost_Function.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
