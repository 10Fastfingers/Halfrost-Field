{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload-images.jianshu.io/upload_images/1194012-9f4d6b21aaf9f39f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一. Building a Spam Classifier\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二. Handling Skewed Data\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三. Using Large Data Sets\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四. Machine Learning System Design 测试\n",
    "\n",
    "\n",
    "### 1. Question 1\n",
    "\n",
    "You are working on a spam classification system using regularized logistic regression. \"Spam\" is a positive class (y = 1) and \"not spam\" is the negative class (y = 0). You have trained your classifier and there are m = 1000 examples in the cross-validation set. The chart of predicted class vs. actual class is:\n",
    "\n",
    "Actual Class: 1\tActual Class: 0\n",
    "Predicted Class: 1\t85\t890\n",
    "Predicted Class: 0\t15\t10\n",
    "\n",
    "For reference:\n",
    "\n",
    "- Accuracy = (true positives + true negatives) / (total examples)\n",
    "- Precision = (true positives) / (true positives + false positives)\n",
    "- Recall = (true positives) / (true positives + false negatives)\n",
    "- F1 score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "What is the classifier's F1 score (as a value from 0 to 1)?\n",
    "\n",
    "Enter your answer in the box below. If necessary, provide at least two values after the decimal point.\n",
    "\n",
    "解答：0.158\n",
    "\n",
    "代入公式 $2\\frac{PR}{P+R}$ 计算即可。\n",
    "\n",
    "### 2. Question 2\n",
    "\n",
    "Suppose a massive dataset is available for training a learning algorithm. Training on a lot of data is likely to give good performance when two of the following conditions hold true.\n",
    "\n",
    "Which are the two?\n",
    "\n",
    "\n",
    "A. When we are willing to include high order polynomial features of x (such as $x_{1}^{2}$, $x_{2}^{2}$,$x_{1}$,$x_{2}$, etc.).\n",
    "\n",
    "B. The features x contain sufficient information to predict y accurately. (For example, one way to verify this is if a human expert on the domain can confidently predict y when given only x).\n",
    "\n",
    "C. We train a learning algorithm with a small number of parameters (that is thus unlikely to overfit).\n",
    "\n",
    "D. We train a learning algorithm with a large number of parameters (that is able to learn/represent fairly complex functions).\n",
    "\n",
    "解答：B、D\n",
    "\n",
    "A. 需要的是足够的特征量而不是高阶。  \n",
    "B. 特征量有足够的信息来准确预测。  \n",
    "C. 少量的特征量显然是不行的。  \n",
    "D. 要有足够多的变量（特征量）。  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3. Question 3\n",
    "\n",
    "Suppose you have trained a logistic regression classifier which is outputing hθ(x).\n",
    "\n",
    "Currently, you predict 1 if $h_{\\theta}(x)\\geqslant threshold$, and predict 0 if $h_{\\theta}(x)<threshold$, where currently the threshold is set to 0.5.\n",
    "\n",
    "Suppose you decrease the threshold to 0.3. Which of the following are true? Check all that apply.\n",
    "\n",
    "\n",
    "A. The classifier is likely to have unchanged precision and recall, but higher accuracy.\n",
    "\n",
    "B. The classifier is likely to now have higher precision.\n",
    "\n",
    "C. The classifier is likely to now have higher recall.\n",
    "\n",
    "D. The classifier is likely to have unchanged precision and recall, but lower accuracy.\n",
    "\n",
    "解答：C\n",
    "\n",
    "将阈值调低的结果只会导致召回率增大，查准率降低。\n",
    "\n",
    "\n",
    "### 4. Question 4\n",
    "\n",
    "Suppose you are working on a spam classifier, where spam emails are positive examples (y=1) and non-spam emails are negative examples (y=0). You have a training set of emails in which 99% of the emails are non-spam and the other 1% is spam. Which of the following statements are true? Check all that apply.\n",
    "\n",
    "\n",
    "A. If you always predict non-spam (output y=0), your classifier will have 99% accuracy on the training set, but it will do much worse on the cross validation set because it has overfit the training data.\n",
    "\n",
    "B. If you always predict non-spam (output y=0), your classifier will have 99% accuracy on the training set, and it will likely perform similarly on the cross validation set.\n",
    "\n",
    "C. A good classifier should have both a high precision and high recall on the cross validation set.\n",
    "\n",
    "D. If you always predict non-spam (output y=0), your classifier will have an accuracy of 99%.\n",
    "\n",
    "解答：B、C、D\n",
    "\n",
    "A. 在交叉验证集因为过拟合的问题会使准确率下降，这不是过拟合的问题，是偏斜类的问题。  \n",
    "B. 假如训练集有99%准确率，那么交叉验证集也有很大可能有99%的准确率，这是正确的，因为数据是随机分布的，训练集的数据分布跟交叉验证集的数据分布相似。  \n",
    "C. 一个好的分类器应该查准率和召回率都比较高，正确。  \n",
    "D. 假如我们都把结果设为全为非垃圾邮件，那么准确率将达到99%，正确。  \n",
    "\n",
    "### 5. Question 5\n",
    "\n",
    "Which of the following statements are true? Check all that apply.\n",
    "\n",
    "\n",
    "A. On skewed datasets (e.g., when there are more positive examples than negative examples), accuracy is not a good measure of performance and you should instead use F1 score based on the precision and recall.\n",
    "\n",
    "\n",
    "B. If your model is underfitting the training set, then obtaining more data is likely to help.\n",
    "\n",
    "\n",
    "C. After training a logistic regression classifier, you must use 0.5 as your threshold for predicting whether an example is positive or negative.\n",
    "\n",
    "\n",
    "D. It is a good idea to spend a lot of time collecting a large amount of data before building your first version of a learning algorithm.\n",
    "\n",
    "\n",
    "E. Using a very large training set makes it unlikely for model to overfit the training data.\n",
    "\n",
    "解答：A、E\n",
    "\n",
    "A.利用 F1 score 去衡量准确性，正确。  \n",
    "B.模型不适合训练集，是欠拟合，欠拟合增大数据样本没用。  \n",
    "C.阈值不一定是0.5。  \n",
    "D.在建立第一个学习算法前花大量时间收集数据显然有可能走向浪费时间的不归路。  \n",
    "E.用更多的数据样本可以解决过拟合的现象，正确。  \n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GitHub Repo：[Halfrost-Field](https://github.com/halfrost/Halfrost-Field)\n",
    "> \n",
    "> Follow: [halfrost · GitHub](https://github.com/halfrost)\n",
    ">\n",
    "> Source: [https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine\\_Learning/Machine\\_Learning\\_System\\_Design.ipynb](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Machine_Learning_System_Design.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
